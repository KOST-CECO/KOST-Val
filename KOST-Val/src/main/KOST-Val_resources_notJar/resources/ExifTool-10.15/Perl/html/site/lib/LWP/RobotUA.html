<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>LWP::RobotUA - a class for well-behaved Web robots</title>
<link rel="stylesheet" href="../../../Active.css" type="text/css" />
<link rev="made" href="mailto:" />
</head>

<body>
<table border="0" width="100%" cellspacing="0" cellpadding="3">
<tr><td class="block" valign="middle">
<big><strong><span class="block">&nbsp;LWP::RobotUA - a class for well-behaved Web robots</span></strong></big>
</td></tr>
</table>

<p><a name="__index__"></a></p>
<!-- INDEX BEGIN -->

<ul>

	<li><a href="#name">NAME</a></li>
	<li><a href="#synopsis">SYNOPSIS</a></li>
	<li><a href="#description">DESCRIPTION</a></li>
	<li><a href="#methods">METHODS</a></li>
	<li><a href="#see_also">SEE ALSO</a></li>
	<li><a href="#copyright">COPYRIGHT</a></li>
</ul>
<!-- INDEX END -->

<hr />
<p>
</p>
<h1><a name="name">NAME</a></h1>
<p>LWP::RobotUA - a class for well-behaved Web robots</p>
<p>
</p>
<hr />
<h1><a name="synopsis">SYNOPSIS</a></h1>
<pre>
  use LWP::RobotUA;
  my $ua = LWP::RobotUA-&gt;new('my-robot/0.1', 'me@foo.com');
  $ua-&gt;delay(10);  # be very nice -- max one hit every ten minutes!
  ...</pre>
<pre>
  # Then just use it just like a normal LWP::UserAgent:
  my $response = $ua-&gt;get('<a href="http://whatever.int/">http://whatever.int/</a>...');
  ...</pre>
<p>
</p>
<hr />
<h1><a name="description">DESCRIPTION</a></h1>
<p>This class implements a user agent that is suitable for robot
applications.  Robots should be nice to the servers they visit.  They
should consult the <em>/robots.txt</em> file to ensure that they are welcomed
and they should not make requests too frequently.</p>
<p>But before you consider writing a robot, take a look at
&lt;URL:http://www.robotstxt.org/&gt;.</p>
<p>When you use a <em>LWP::RobotUA</em> object as your user agent, then you do not
really have to think about these things yourself; <code>robots.txt</code> files
are automatically consulted and obeyed, the server isn't queried
too rapidly, and so on.  Just send requests
as you do when you are using a normal <em>LWP::UserAgent</em>
object (using <code>$ua-&gt;get(...)</code>, <code>$ua-&gt;head(...)</code>,
<code>$ua-&gt;request(...)</code>, etc.), and this
special agent will make sure you are nice.</p>
<p>
</p>
<hr />
<h1><a name="methods">METHODS</a></h1>
<p>The LWP::RobotUA is a sub-class of LWP::UserAgent and implements the
same methods. In addition the following methods are provided:</p>
<dl>
<dt><strong><a name="item_new">$ua = LWP::RobotUA-&gt;new( %options )</a></strong><br />
</dt>
<dt><strong>$ua = LWP::RobotUA-&gt;new( $agent, $from )</strong><br />
</dt>
<dt><strong>$ua = LWP::RobotUA-&gt;new( $agent, $from, $rules )</strong><br />
</dt>
<dd>
The LWP::UserAgent options <code>agent</code> and <code>from</code> are mandatory.  The
options <a href="#item_delay"><code>delay</code></a>, <a href="#item_use_sleep"><code>use_sleep</code></a> and <a href="#item_rules"><code>rules</code></a> initialize attributes
private to the RobotUA.  If <a href="#item_rules"><code>rules</code></a> are not provided, then
<code>WWW::RobotRules</code> is instantiated providing an internal database of
<em>robots.txt</em>.
</dd>
<dd>
<p>It is also possible to just pass the value of <code>agent</code>, <code>from</code> and
optionally <a href="#item_rules"><code>rules</code></a> as plain positional arguments.</p>
</dd>
<p></p>
<dt><strong><a name="item_delay">$ua-&gt;delay</a></strong><br />
</dt>
<dt><strong>$ua-&gt;delay( $minutes )</strong><br />
</dt>
<dd>
Get/set the minimum delay between requests to the same server, in
<em>minutes</em>.  The default is 1 minute.  Note that this number doesn't
have to be an integer; for example, this sets the delay to 10 seconds:
</dd>
<dd>
<pre>
    $ua-&gt;delay(10/60);</pre>
</dd>
<p></p>
<dt><strong><a name="item_use_sleep">$ua-&gt;use_sleep</a></strong><br />
</dt>
<dt><strong>$ua-&gt;use_sleep( $boolean )</strong><br />
</dt>
<dd>
Get/set a value indicating whether the UA should <a href="../../../lib/Pod/perlfunc.html#item_sleep"><code>sleep()</code></a> if requests
arrive too fast, defined as $ua-&gt;delay minutes not passed since
last request to the given server.  The default is TRUE.  If this value is
FALSE then an internal SERVICE_UNAVAILABLE response will be generated.
It will have an Retry-After header that indicates when it is OK to
send another request to this server.
</dd>
<p></p>
<dt><strong><a name="item_rules">$ua-&gt;rules</a></strong><br />
</dt>
<dt><strong>$ua-&gt;rules( $rules )</strong><br />
</dt>
<dd>
Set/get which <em>WWW::RobotRules</em> object to use.
</dd>
<p></p>
<dt><strong><a name="item_no_visits">$ua-&gt;no_visits( $netloc )</a></strong><br />
</dt>
<dd>
Returns the number of documents fetched from this server host. Yeah I
know, this method should probably have been named <code>num_visits()</code> or
something like that. :-(
</dd>
<p></p>
<dt><strong><a name="item_host_wait">$ua-&gt;host_wait( $netloc )</a></strong><br />
</dt>
<dd>
Returns the number of <em>seconds</em> (from now) you must wait before you can
make a new request to this host.
</dd>
<p></p>
<dt><strong><a name="item_as_string">$ua-&gt;as_string</a></strong><br />
</dt>
<dd>
Returns a string that describes the state of the UA.
Mainly useful for debugging.
</dd>
<p></p></dl>
<p>
</p>
<hr />
<h1><a name="see_also">SEE ALSO</a></h1>
<p><a href="../../../site/lib/LWP/UserAgent.html">the LWP::UserAgent manpage</a>, <a href="../../../site/lib/WWW/RobotRules.html">the WWW::RobotRules manpage</a></p>
<p>
</p>
<hr />
<h1><a name="copyright">COPYRIGHT</a></h1>
<p>Copyright 1996-2004 Gisle Aas.</p>
<p>This library is free software; you can redistribute it and/or
modify it under the same terms as Perl itself.</p>
<table border="0" width="100%" cellspacing="0" cellpadding="3">
<tr><td class="block" valign="middle">
<big><strong><span class="block">&nbsp;LWP::RobotUA - a class for well-behaved Web robots</span></strong></big>
</td></tr>
</table>

</body>

</html>
